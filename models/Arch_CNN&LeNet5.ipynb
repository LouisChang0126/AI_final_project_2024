{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1448722,"sourceType":"datasetVersion","datasetId":849193}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook compares the model performance between two CNN architectures - LeNet-5 and a custom CNN comically called ArchiNet - to solve multiclass image classification of the architectural style of a building from a given image.  The images dataset was retrieved from here: https://www.kaggle.com/datasets/dumitrux/architectural-styles-dataset.  After the models are trained, their performances are evaluated through visualizations.","metadata":{}},{"cell_type":"markdown","source":"# **Import Required Libraries**","metadata":{}},{"cell_type":"code","source":"# Suppress warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:22:11.732326Z","iopub.execute_input":"2024-03-15T23:22:11.7329Z","iopub.status.idle":"2024-03-15T23:22:11.777642Z","shell.execute_reply.started":"2024-03-15T23:22:11.732856Z","shell.execute_reply":"2024-03-15T23:22:11.776299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport json\nimport itertools\nimport glob\nimport sys\nimport requests\nimport random\nimport pickle\nimport joblib\nimport imageio\nimport PIL\nfrom tabulate import tabulate\nfrom pathlib import Path\nfrom PIL import ImageFont, Image\n\n# Machine learning libraries\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\nfrom skimage.transform import resize\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D, AveragePooling2D, Reshape\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Suppress Tensorflow warnings and errors\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T23:22:11.780808Z","iopub.execute_input":"2024-03-15T23:22:11.781872Z","iopub.status.idle":"2024-03-15T23:22:27.307437Z","shell.execute_reply.started":"2024-03-15T23:22:11.781812Z","shell.execute_reply":"2024-03-15T23:22:27.306054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Numpy version: \", np.__version__)\nprint(\"Pandas version: \", pd.__version__)\nprint(\"CV2 version: \", cv2.__version__)\nprint(\"TensorFlow version: \", tf.__version__)\nprint(\"Keras version: \", keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:22:27.309538Z","iopub.execute_input":"2024-03-15T23:22:27.310487Z","iopub.status.idle":"2024-03-15T23:22:27.318677Z","shell.execute_reply.started":"2024-03-15T23:22:27.310443Z","shell.execute_reply":"2024-03-15T23:22:27.317046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Any edits to libraries are reloaded automatically\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:22:27.32221Z","iopub.execute_input":"2024-03-15T23:22:27.322656Z","iopub.status.idle":"2024-03-15T23:22:27.444743Z","shell.execute_reply.started":"2024-03-15T23:22:27.322621Z","shell.execute_reply":"2024-03-15T23:22:27.443757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training, Validation, and Test Sets**","metadata":{}},{"cell_type":"code","source":"styles = ['Achaemenid architecture','American craftsman style','American Foursquare architecture','Ancient Egyptian architecture','Art Deco architecture',\n    'Art Nouveau architecture','Baroque architecture','Bauhaus architecture','Beaux-Arts architecture','Byzantine architecture',\n    'Chicago school architecture','Colonial architecture','Deconstructivism','Edwardian architecture','Georgian architecture',\n    'Gothic architecture','Greek Revival architecture','International style','Novelty architecture','Palladian architecture',\n    'Postmodern architecture','Queen Anne architecture','Romanesque architecture','Russian Revival architecture','Tudor Revival architecture']","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:22:27.446208Z","iopub.execute_input":"2024-03-15T23:22:27.446804Z","iopub.status.idle":"2024-03-15T23:22:27.551889Z","shell.execute_reply.started":"2024-03-15T23:22:27.446768Z","shell.execute_reply":"2024-03-15T23:22:27.550744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate image dataset into features and labels (target = style)\nX = []\ny = []\n\n# Set size for images to be resized to\nsize = (256, 256)\n\n# Put images in X and their labels in y\nfor style in styles[:]:\n    img_file = glob.glob(f'../input/architectural-styles-dataset/**/{style}/*.jpg', recursive = True)\n    \n    # Resize and grayscale each image\n    for i, f in enumerate(img_file):\n        img = cv2.imread(f)\n        img = cv2.resize(img, size, interpolation = cv2.INTER_AREA)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = np.array(img)\n        img = img.astype('float32')\n        img /= 255 \n        X.append(img)\n        y.append(style)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:22:27.55441Z","iopub.execute_input":"2024-03-15T23:22:27.554992Z","iopub.status.idle":"2024-03-15T23:27:09.142312Z","shell.execute_reply.started":"2024-03-15T23:22:27.55491Z","shell.execute_reply":"2024-03-15T23:27:09.140342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cast labels to integers \ny = [styles.index(label) for label in y]\n\n# Create training, validation, and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:09.145688Z","iopub.execute_input":"2024-03-15T23:27:09.146286Z","iopub.status.idle":"2024-03-15T23:27:09.29271Z","shell.execute_reply.started":"2024-03-15T23:27:09.146231Z","shell.execute_reply":"2024-03-15T23:27:09.29126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display length of X and y\n# Should be the same and reflect number of images from dataset\nprint(f'Length of X: {len(X)}')\nprint(f'Length of y: {len(y)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:09.296187Z","iopub.execute_input":"2024-03-15T23:27:09.296564Z","iopub.status.idle":"2024-03-15T23:27:09.403179Z","shell.execute_reply.started":"2024-03-15T23:27:09.296534Z","shell.execute_reply":"2024-03-15T23:27:09.401482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check lengths of training, validation, and test sets\nprint(\"Length of X_train: \", len(X_train))\nprint(\"Length of y_train: \", len(y_train))\nprint(\"Length of X_valid: \", len(X_valid))\nprint(\"Length of y_valid: \", len(y_valid))\nprint(\"Length of X_test: \", len(X_test))\nprint(\"Length of y_test: \", len(y_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:09.404813Z","iopub.execute_input":"2024-03-15T23:27:09.405363Z","iopub.status.idle":"2024-03-15T23:27:09.510925Z","shell.execute_reply.started":"2024-03-15T23:27:09.40531Z","shell.execute_reply":"2024-03-15T23:27:09.509086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sets arrays for model fitting\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)\nX_valid = np.asarray(X_valid)\ny_valid = np.asarray(y_valid)\nX_test = np.asarray(X_test)\ny_test = np.asarray(y_test)\n\ntype(X_train), type(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:09.516649Z","iopub.execute_input":"2024-03-15T23:27:09.51728Z","iopub.status.idle":"2024-03-15T23:27:12.516749Z","shell.execute_reply.started":"2024-03-15T23:27:09.517238Z","shell.execute_reply":"2024-03-15T23:27:12.515067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Build and Train Models**","metadata":{}},{"cell_type":"markdown","source":"## *LeNet-5 CNN*\n\nLeNet-5 CNN architecture retrieved from:\nhttps://towardsdatascience.com/convolutional-neural-network-champions-part-1-lenet-5-7a8d6eb98df6","metadata":{}},{"cell_type":"code","source":"# Create function for LeNet-5 CNN model\ndef lenet5():\n    model = Sequential()\n    model.add(Reshape((256, 256, 1), input_shape=(256, 256), name='Reshape'))\n    model.add(Conv2D(input_shape=(32, 32, 1), filters=6, kernel_size=(5, 5), strides=(1, 1), padding=\"same\", activation='tanh', name='Conv2D_1'))\n    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='AvgPool2D_1'))\n    model.add(Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='tanh', name='Conv2D_2'))\n    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name='AvgPool2D_2'))\n    model.add(Flatten(name='Flatten'))\n    model.add(Dense(120, activation='tanh', name='Dense_1'))\n    model.add(Dense(84, activation='tanh', name='Dense_2'))\n    model.add(Dense(25, activation='softmax', name='Dense_3'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:12.518402Z","iopub.execute_input":"2024-03-15T23:27:12.518776Z","iopub.status.idle":"2024-03-15T23:27:12.629442Z","shell.execute_reply.started":"2024-03-15T23:27:12.518745Z","shell.execute_reply":"2024-03-15T23:27:12.627818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign LeNet-5\nLeNet5 = lenet5()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:12.631345Z","iopub.execute_input":"2024-03-15T23:27:12.631782Z","iopub.status.idle":"2024-03-15T23:27:13.183093Z","shell.execute_reply.started":"2024-03-15T23:27:12.631746Z","shell.execute_reply":"2024-03-15T23:27:13.181454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View summary for LeNet-5\nprint(LeNet5.summary(line_length = 120))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:13.184949Z","iopub.execute_input":"2024-03-15T23:27:13.185443Z","iopub.status.idle":"2024-03-15T23:27:13.337875Z","shell.execute_reply.started":"2024-03-15T23:27:13.185406Z","shell.execute_reply":"2024-03-15T23:27:13.33605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and loss function for LeNet-5\nlenet5_early_stop = EarlyStopping(monitor = 'val_accuracy', mode = 'max', verbose = 1, patience = 2)\nlenet5_opt = SGD(learning_rate = 0.01, momentum = 0.0, nesterov = 'False')\nlenet5_loss = SparseCategoricalCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:13.340129Z","iopub.execute_input":"2024-03-15T23:27:13.341286Z","iopub.status.idle":"2024-03-15T23:27:13.465675Z","shell.execute_reply.started":"2024-03-15T23:27:13.341229Z","shell.execute_reply":"2024-03-15T23:27:13.463722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile LeNet-5 CNN model\nLeNet5.compile(loss = lenet5_loss, optimizer = lenet5_opt, metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:13.46777Z","iopub.execute_input":"2024-03-15T23:27:13.468274Z","iopub.status.idle":"2024-03-15T23:27:13.600668Z","shell.execute_reply.started":"2024-03-15T23:27:13.468234Z","shell.execute_reply":"2024-03-15T23:27:13.599295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train LeNet-5 on training set and validate with validation set\nlenet5_history = LeNet5.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = 15, shuffle = True, callbacks = lenet5_early_stop)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T23:27:13.602378Z","iopub.execute_input":"2024-03-15T23:27:13.603523Z","iopub.status.idle":"2024-03-16T00:33:30.474863Z","shell.execute_reply.started":"2024-03-15T23:27:13.603486Z","shell.execute_reply":"2024-03-16T00:33:30.473841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate loss and accuracy from test set\nLeNet5.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:33:30.476394Z","iopub.execute_input":"2024-03-16T00:33:30.477251Z","iopub.status.idle":"2024-03-16T00:33:57.714651Z","shell.execute_reply.started":"2024-03-16T00:33:30.477208Z","shell.execute_reply":"2024-03-16T00:33:57.713481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nLeNet5.save('LeNet5.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:33:57.716386Z","iopub.execute_input":"2024-03-16T00:33:57.717383Z","iopub.status.idle":"2024-03-16T00:33:57.947218Z","shell.execute_reply.started":"2024-03-16T00:33:57.71734Z","shell.execute_reply":"2024-03-16T00:33:57.94575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model (for when the same kernel instance isn't in use)\nLeNet5 = load_model('LeNet5.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:33:57.948847Z","iopub.execute_input":"2024-03-16T00:33:57.949295Z","iopub.status.idle":"2024-03-16T00:33:58.417177Z","shell.execute_reply.started":"2024-03-16T00:33:57.949257Z","shell.execute_reply":"2024-03-16T00:33:58.415594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the history (fit) of model\nwith open('LeNet5TrainingHistory', 'wb') as file:\n    pickle.dump(lenet5_history.history, file)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:33:58.419394Z","iopub.execute_input":"2024-03-16T00:33:58.419986Z","iopub.status.idle":"2024-03-16T00:33:58.527702Z","shell.execute_reply.started":"2024-03-16T00:33:58.419917Z","shell.execute_reply":"2024-03-16T00:33:58.52578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load saved history (fit) of model (for when the same kernel instance isn't in use)\nwith open('LeNet5TrainingHistory', \"rb\") as file:\n    lenet5_history = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:33:58.530358Z","iopub.execute_input":"2024-03-16T00:33:58.530854Z","iopub.status.idle":"2024-03-16T00:33:58.637605Z","shell.execute_reply.started":"2024-03-16T00:33:58.530813Z","shell.execute_reply":"2024-03-16T00:33:58.635368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make prediciton on first image in test set\nlenet5_pred = LeNet5.predict(X_test)\nlenet5_pred[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:33:58.639842Z","iopub.execute_input":"2024-03-16T00:33:58.640449Z","iopub.status.idle":"2024-03-16T00:34:26.179707Z","shell.execute_reply.started":"2024-03-16T00:33:58.640399Z","shell.execute_reply":"2024-03-16T00:34:26.178201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a quick comparison of the predicted label vs actual label of first test sample\nprint(f'Predicted encoded label of first test sample: {np.argmax(lenet5_pred[0])}')\nprint(f'Actual encoded label of first test sample: {y_test[0]}')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:26.181576Z","iopub.execute_input":"2024-03-16T00:34:26.18315Z","iopub.status.idle":"2024-03-16T00:34:26.291304Z","shell.execute_reply.started":"2024-03-16T00:34:26.183094Z","shell.execute_reply":"2024-03-16T00:34:26.289767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Max prediction of each label for each image\nlenet5_y_pred = np.argmax(lenet5_pred, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:26.293507Z","iopub.execute_input":"2024-03-16T00:34:26.29405Z","iopub.status.idle":"2024-03-16T00:34:26.394835Z","shell.execute_reply.started":"2024-03-16T00:34:26.294005Z","shell.execute_reply":"2024-03-16T00:34:26.39343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first 25 images from test set and the predicted label\nfig, ax = plt.subplots(ncols = 5, nrows = 5, figsize = (12, 12))\nax = ax.flatten()\n\nfor i, img in enumerate(X_test[:25]):\n    ax[i].axis('off')\n    ax[i].imshow(img, cmap = \"binary\", interpolation = \"nearest\")\n    ax[i].set_title(styles[lenet5_y_pred[i]], fontsize = 9)\n\nfig.suptitle('LeNet5 Test Dataset Predictions', fontsize = 16)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:26.39741Z","iopub.execute_input":"2024-03-16T00:34:26.398489Z","iopub.status.idle":"2024-03-16T00:34:29.019509Z","shell.execute_reply.started":"2024-03-16T00:34:26.398433Z","shell.execute_reply":"2024-03-16T00:34:29.018262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Custom CNN - ArchiNet*","metadata":{}},{"cell_type":"code","source":"def archinet():\n    model = Sequential()\n    model.add(Reshape((256, 256, 1), input_shape=(256, 256), name='Reshape'))\n    model.add(Conv2D(input_shape=(256, 256, 3), filters=6, kernel_size=(3, 3), padding='same', activation='relu', name='Conv2D_1'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='MaxPool2D_1'))\n    model.add(Conv2D(filters=24, kernel_size=(3, 3), padding='same', activation='relu', name='Conv2D_2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='MaxPool2D_2'))\n    model.add(Conv2D(filters=48, kernel_size=(3, 3), padding='same', activation='relu', name='Conv2D_3'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='MaxPool2D_3'))\n    model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='same', activation='relu', name='Conv2D_4'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='MaxPool2D_4'))\n    model.add(Flatten(name='Flatten'))\n    model.add(Dense(125, activation='relu', name='Dense_1'))\n    model.add(Dense(75, activation='relu', name='Dense_2'))\n    model.add(Dense(25, activation='softmax', name='Dense_3'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:29.020797Z","iopub.execute_input":"2024-03-16T00:34:29.021213Z","iopub.status.idle":"2024-03-16T00:34:29.147776Z","shell.execute_reply.started":"2024-03-16T00:34:29.021177Z","shell.execute_reply":"2024-03-16T00:34:29.146031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign custom CNN\nArchiNet = archinet()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:29.148999Z","iopub.execute_input":"2024-03-16T00:34:29.149443Z","iopub.status.idle":"2024-03-16T00:34:29.462633Z","shell.execute_reply.started":"2024-03-16T00:34:29.1494Z","shell.execute_reply":"2024-03-16T00:34:29.461267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View summary for custom CNN\nprint(ArchiNet.summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:29.472773Z","iopub.execute_input":"2024-03-16T00:34:29.473829Z","iopub.status.idle":"2024-03-16T00:34:29.62677Z","shell.execute_reply.started":"2024-03-16T00:34:29.473772Z","shell.execute_reply":"2024-03-16T00:34:29.625524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define callback (early stopping), optimizer and loss function for Custom CNN\narchinet_early_stop = EarlyStopping(monitor = 'val_accuracy', mode = 'max', verbose = 1, patience = 5)\narchinet_opt = Adam(learning_rate = 0.001)\narchinet_loss = SparseCategoricalCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:29.628662Z","iopub.execute_input":"2024-03-16T00:34:29.629104Z","iopub.status.idle":"2024-03-16T00:34:29.735737Z","shell.execute_reply.started":"2024-03-16T00:34:29.629067Z","shell.execute_reply":"2024-03-16T00:34:29.733859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile Custom CNN model\nArchiNet.compile(loss = archinet_loss, optimizer = archinet_opt, metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:29.737036Z","iopub.execute_input":"2024-03-16T00:34:29.737676Z","iopub.status.idle":"2024-03-16T00:34:29.861445Z","shell.execute_reply.started":"2024-03-16T00:34:29.737617Z","shell.execute_reply":"2024-03-16T00:34:29.859447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Custom CNN on training set and validate with validation set\narchinet_history = ArchiNet.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = 30, shuffle = True, callbacks = archinet_early_stop)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T00:34:29.863775Z","iopub.execute_input":"2024-03-16T00:34:29.864234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate loss and accuracy from test set\nArchiNet.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nArchiNet.save('ArchiNet.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model (for when the same kernel instance isn't in use)\nArchiNet = load_model('ArchiNet.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the history (fit) of model\nwith open('ArchiNetTrainingHistory', 'wb') as file:\n    pickle.dump(archinet_history.history, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load saved history (fit) of model (for when the same kernel instance isn't in use)\nwith open('ArchiNetTrainingHistory', \"rb\") as file:\n    archinet_history = pickle.load(file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make prediciton on first image in test set\narchinet_pred = ArchiNet.predict(X_test)\narchinet_pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a quick comparison of the predicted label vs actual label of first test sample\nprint(f'Predicted encoded label of first test sample: {np.argmax(archinet_pred[0])}')\nprint(f'Actual encoded label of first test sample: {y_test[0]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Max prediction of each label for each image\narchinet_y_pred = np.argmax(archinet_pred, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display first 25 images from test set and the predicted label\nfig, ax = plt.subplots(ncols = 5, nrows = 5, figsize = (12, 12))\nax = ax.flatten()\n\nfor i, img in enumerate(X_test[:25]):\n    ax[i].axis('off')\n    ax[i].imshow(img, cmap = \"binary\", interpolation = \"nearest\")\n    ax[i].set_title(styles[archinet_y_pred[i]], fontsize = 9)\n\nfig.suptitle('ArchiNet Test Dataset Predictions', fontsize = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualize Model Performance**","metadata":{}},{"cell_type":"markdown","source":"## *LeNet-5 CNN*","metadata":{}},{"cell_type":"code","source":"# Print performance evaluation metrics for model\nprint(f\"LeNet-5 Accuracy Score: {accuracy_score(lenet5_y_pred, y_test)}\")\nprint(f\"LeNet-5 Precision Score: {precision_score(lenet5_y_pred, y_test, average = 'weighted')}\")\nprint(f\"LeNet-5 Recall Score: {recall_score(lenet5_y_pred, y_test, average = 'weighted')}\")\nprint(f\"LeNet-5 F1 Score: {f1_score(lenet5_y_pred, y_test, average = 'weighted')}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot LeNet-5 accuracy and loss for training and validation sets from model history\nplt.subplots(figsize = (10, 5))\nplt.subplots_adjust(wspace = 0.5)\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.grid('on')\nplt.plot(lenet5_history['accuracy'], color = \"green\")\nplt.plot(lenet5_history['val_accuracy'], color = \"blue\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('LeNet-5 Accuracy', fontsize = 15, fontweight = \"bold\")\nplt.legend(['Training', 'Validation'], loc = 'upper left')\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.grid('on')\nplt.plot(lenet5_history['loss'], color = \"red\")\nplt.plot(lenet5_history['val_loss'], color = \"black\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('LeNet-5 Loss', fontsize = 15, fontweight = \"bold\")\nplt.legend(['Training', 'Validation'], loc = 'upper left')\n\n# Show plots\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create y_true variable to represent the actual labels from y_test\n# Will be used across all confusion matrices\ny_true = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create confusion matrix from model predictions\nlenet5_conf_mtx = confusion_matrix(y_true, lenet5_y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display confusion matrix\nfig = plt.figure(figsize = (16, 14))\nax = plt.subplot()\n\n# Set heatmap for confusion matrix\nsns.heatmap(lenet5_conf_mtx, annot = True, ax = ax, cmap = \"icefire\", fmt = 'g')\n\n# Set axes labels\nax.xaxis.set_label_position('bottom')\nax.set_xlabel('Predicted', fontsize = 20)\nax.set_ylabel('True', fontsize = 20)\n\n# Set axes ticks\nax.xaxis.tick_bottom()\nax.xaxis.set_ticklabels(styles, fontsize = 10)\nax.yaxis.set_ticklabels(styles, fontsize = 10)\nplt.xticks(rotation = 90)\nplt.yticks(rotation = 0)\n\nplt.title('LeNet-5 Confusion Matrix', fontsize = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create list to append X_test images that were incorrectly predicted\nlenet5_wrong = []\n\nfor i in range(len(lenet5_y_pred)):\n    if lenet5_y_pred[i] != y_true[i]:\n        lenet5_wrong.append(X_test[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display 25 wrong predictions\nfig, ax = plt.subplots(ncols = 5, nrows = 5, figsize = (12, 12))\nax = ax.flatten()\n\n# Set random starting point and ending point\nrand_start = random.randint(0, 300)\nrand_end = rand_start + 25\n\nfor i, img in enumerate(lenet5_wrong[rand_start:rand_end]):\n    ax[i].axis('off')\n    ax[i].imshow(img, cmap = \"binary\", interpolation = \"nearest\")\n    ax[i].set_title(styles[lenet5_y_pred[i]], fontsize = 9)\n\nfig.suptitle('LeNet-5 Wrong Predictions', fontsize = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Custom CNN - ArchiNet*","metadata":{}},{"cell_type":"code","source":"# Print performance evaluation metrics for model\nprint(f\"ArchiNet Accuracy Score: {accuracy_score(archinet_y_pred, y_test)}\")\nprint(f\"ArchiNet Precision Score: {precision_score(archinet_y_pred, y_test, average = 'weighted')}\")\nprint(f\"ArchiNet Recall Score: {recall_score(archinet_y_pred, y_test, average = 'weighted')}\")\nprint(f\"ArchiNet F1 Score: {f1_score(archinet_y_pred, y_test, average = 'weighted')}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot accuracy and loss for training and validation sets from model history\nplt.subplots(figsize = (10, 5))\nplt.subplots_adjust(wspace = 0.5)\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.grid('on')\nplt.plot(archinet_history['accuracy'], color = \"green\")\nplt.plot(archinet_history['val_accuracy'], color = \"blue\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('ArchiNet Accuracy', fontsize = 15, fontweight = \"bold\")\nplt.legend(['Training', 'Validation'], loc = 'upper left')\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.grid('on')\nplt.plot(archinet_history['loss'], color = \"red\")\nplt.plot(archinet_history['val_loss'], color = \"black\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('ArchiNet Loss', fontsize = 15, fontweight = \"bold\")\nplt.legend(['Training', 'Validation'], loc = 'upper left')\n\n# Show plots\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create confusion matrix from model predictions\narchinet_conf_mtx = confusion_matrix(y_true, archinet_y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display confusion matrix\nfig = plt.figure(figsize = (16, 14))\nax = plt.subplot()\n\n# Set heatmap for confusion matrix\nsns.heatmap(archinet_conf_mtx, annot = True, ax = ax, cmap = \"mako\", fmt = 'g')\n\n# Set axes labels\nax.xaxis.set_label_position('bottom')\nax.set_xlabel('Predicted', fontsize = 20)\nax.set_ylabel('True', fontsize = 20)\n\n# Set axes ticks\nax.xaxis.tick_bottom()\nax.xaxis.set_ticklabels(styles, fontsize = 10)\nax.yaxis.set_ticklabels(styles, fontsize = 10)\nplt.xticks(rotation = 90)\nplt.yticks(rotation = 0)\n\nplt.title('ArchiNet Confusion Matrix', fontsize = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create list to append X_test images that were incorrectly predicted\narchinet_wrong = []\n\nfor i in range(len(archinet_y_pred)):\n    if archinet_y_pred[i] != y_true[i]:\n        archinet_wrong.append(X_test[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display 25 wrong predictions\nfig, ax = plt.subplots(ncols = 5, nrows = 5, figsize = (12, 12))\nax = ax.flatten()\n\n# Set random starting point and ending point\nrand_start = random.randint(0, 300)\nrand_end = rand_start + 25\n\nfor i, img in enumerate(archinet_wrong[rand_start:rand_end]):\n    ax[i].axis('off')\n    ax[i].imshow(img, cmap = \"binary\", interpolation = \"nearest\")\n    ax[i].set_title(styles[archinet_y_pred[i]], fontsize = 9)\n\nfig.suptitle('ArchiNet Wrong Predictions', fontsize = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print summary of performance metrics comparing CNNs\nprint(tabulate([['Lenet-5', 'Accuracy', '{:,.2%}'.format(accuracy_score(lenet5_y_pred, y_test))], \n                ['', 'Precision', '{:,.2%}'.format(precision_score(lenet5_y_pred, y_test, average = 'weighted'))],\n                ['', 'Recall', '{:,.2%}'.format(recall_score(lenet5_y_pred, y_test, average = 'weighted'))],\n                ['', 'F1', '{:,.2%}'.format(f1_score(lenet5_y_pred, y_test, average = 'weighted'))],\n                ['', '', '', ''],\n                ['Archinet', 'Accuracy', '{:,.2%}'.format(accuracy_score(archinet_y_pred, y_test))], \n                ['', 'Precision', '{:,.2%}'.format(precision_score(archinet_y_pred, y_test, average = 'weighted'))],\n                ['', 'Recall', '{:,.2%}'.format(recall_score(archinet_y_pred, y_test, average = 'weighted'))],\n                ['', 'F1', '{:,.2%}'.format(f1_score(archinet_y_pred, y_test, average = 'weighted'))]],\n               headers=['Model', 'Metric', 'Performance']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}